{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python Exercises\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
    "\n",
    "\n",
    "### This is a 30 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end. If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation. (Note, not all questions have tests).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME = \"Jason Kuruzovich\"\n",
    "COLLABORATORS = [\"Alyssa Hacker\"]  #You can speak with others regarding the assignment, but all typed work must be your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you have trouble loading your unittests below, \n",
    "#!conda config --add channels conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!conda install --quiet ipython_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Loads a Testing Array \n",
    "- This runs tests against your b array.  If you complete the assingment correctly, you will pass the tests. \n",
    "- **If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext ipython_unittest\n",
    "#This runs tests against your b array.  If you complete the assingment correctly, you will pass the tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise-Pandas\n",
    "(1) Using, the Iris dataset, find the mean of the sepalLength and assign it to the `sepal_length_mean` variable using the dataframe returned from the describe command.  \n",
    "\n",
    "(2) Create a new dataframe `iristrain` that includes the first 75 rows of the iris dataframe.\n",
    "\n",
    "(3) Create a new dataframe `iristest` that includes the last 75 rows of the iris dataframe.\n",
    "\n",
    "(4) Create a new series `sepal_length` from the `sepal_length` column of the iris dataframe. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%unittest_main\n",
    "class TestPandas(unittest.TestCase):\n",
    "    def test_pandas1(self):\n",
    "        self.assertAlmostEqual(sepal_length_mean, 5.8433333333333337)\n",
    "    def test_pandas2(self):\n",
    "        self.assertTrue(iristrain.describe().sepal_length['count'] == 75.0)\n",
    "    def test_pandas3(self):\n",
    "        self.assertTrue(iristest.describe().sepal_length['count'] == 75.0)\n",
    "    def test_pandas4(self):\n",
    "        self.assertAlmostEqual(iristrain.describe().sepal_length['std'], 0.63842994352770832)\n",
    "    def test_pandas5(self):\n",
    "        self.assertAlmostEqual(iristest.describe().sepal_length['std'], 0.67988340282833903)\n",
    "    def test_pandas6(self):\n",
    "        self.assertAlmostEqual(sepal_Length[134], 6.0999999999999996)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - For and If.\n",
    "\n",
    "(5). Write a program which create a list `div7not5` of all numbers which are divisible by 7 but are not a multiple of 5,\n",
    "between 10000 and 10100 (both included). *Hint: 10 is divisible by five if 10%5==0*. \n",
    "\n",
    "**Note: Each item in the list should be a string to past the test.** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Functions\n",
    "\n",
    "(6). Create a function `divby2` that accepts a list and returns all values from that list that are divisible by 2.  For example, passing the list  `numbers = [3, 12, 91, 33, 21, 34, 54, 34, 34, 54]` should return a list. Generate a new list `divby2` that includes only numbers that are divisible by 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define your function here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Execute this code\n",
    "numbers = [3, 12, 91, 33, 21, 34, 54, 34, 34, 54]\n",
    "divby2=divby2(numbers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Create an external module for your `divby2` function called myutilities.  Import myutilities as mu, such that that following runs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After importing this should work. (Feel free to add code to reimport)\n",
    "import myutilities as mu\n",
    "divby2mod=mu.divby2(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises-Titanic\n",
    "\n",
    "The following exercises will use the titanic data from Kaggle.  I've included it in the input folder just like Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# Let's input them into a Pandas DataFrame\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test  = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(8). While we can submit our answer to Kaggle to see how it will perform, we can also utilize our test data to assess accuracy. Accuracy is the percentage of predictions made correctly-i.e., the percentage of people in which our prediction regarding their survival. <br>\n",
    "    a. Create columns in the training dataset `PredEveryoneDies` and `PredGender` with the same predictions which were included in the example notebook (06-intro-kaggle-baseline in the materials repository).   \n",
    "    b. Create variables `AccEveryoneDies` and `AccGender` using a calculation of accuracy of predictions for the `training` dataset.    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9). Notice how we are utilizing the code to select out the `passengerID` and the `Survived` column and generating a submission file over and over? This is in need of a function.  Create a `generate_submission` function that accepts a DataFrame, a target column, and a filename and writes out the submission file with just the `passengerID` and the `Survived` columns, where the survived column is equal to the target column. It should then return a DataFrame with the `passengerID` and the `Survived` columns.\n",
    "\n",
    "Executeing the following:\n",
    "`submitdie = generate_submission(train, 'PredEveryoneDies', 'submiteveryonedies.csv')`\n",
    "\n",
    "Should return a dataframe with just `passengerID` and the `Survived` column.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(10). In accordance to the [women and children first](https://en.wikipedia.org/wiki/Women_and_children_first) protocol, we hypothesize that our model could be improved by including whether the individual was a child in addition to gender.  *After* coding survival based on gender, update your recommendation to prediction in the training dataset survival based on age. <br> <br>\n",
    "\n",
    "In other words, your model should predict that a male child would survive.  \n",
    "\n",
    "\n",
    "\n",
    "`train['PredGenderAge13']` should be the prediction incorporating both Gender and whether Age <  13.\n",
    "`train['PredGenderAge18']` should be the prediction incorporating both Gender and whether Age <  18.\n",
    "`AccGenderAge13` should be the accuracy of the age prediction, based on `train['PredGenderAge13']`. \n",
    "`AccGenderAge18` should be the accuracy of the age prediction, based on `train['PredGenderAge18']`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11) Create a prediction file for the \"women and children first\" model in column` PredGenderAge13` and upload it to Kaggle.  Take a screen shot of your position. Put that screenshot in this repository and use markdown to show your results in the cell below.  The syntax for including a markdown picture is shown below.  \n",
    "\n",
    "```\n",
    "![]myscreenshot.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do your markdown here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12). You should find that the AccGenderAge13 is better than AccGenderAge18. Create a new column `child` in the test and train DataFrames that is 1 if Age <  13 and 0 otherwise.  This is a *feature*.  We will talk more about features next time.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(13) Use the groupby command to simultanously examine the likelyhood of surving using `gender`, `pclass`, and your new `child` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%unittest_main\n",
    "class TestExercise3(unittest.TestCase):\n",
    "    def test_pandas1(self):\n",
    "        self.assertAlmostEqual(sepalLengthMean, 5.8433333333333337)\n",
    "    def test_pandas2(self):\n",
    "        self.assertTrue(iristrain.describe().sepalLength['count'] == 75.0)\n",
    "    def test_pandas3(self):\n",
    "        self.assertTrue(iristest.describe().sepalLength['count'] == 75.0)\n",
    "    def test_pandas4(self):\n",
    "        self.assertAlmostEqual(iristrain.describe().sepalLength['std'], 0.63842994352770832)\n",
    "    def test_pandas5(self):\n",
    "        self.assertAlmostEqual(iristest.describe().sepalLength['std'], 0.67988340282833903)\n",
    "    def test_pandas6(self):\n",
    "        self.assertAlmostEqual(sepalLength[134], 6.0999999999999996)\n",
    "    def test_forif(self):\n",
    "        self.assertTrue(div7not5 == ['10003', '10017', '10024', '10031', '10038', '10052', '10059', '10066', '10073', '10087', '10094'])\n",
    "    def test_functions(self):\n",
    "        self.assertTrue(divby2 == [12, 34, 54, 34, 34, 54])\n",
    "    def test_functions(self):\n",
    "        self.assertTrue(divby2mod == [12, 34, 54, 34, 34, 54])\n",
    "    def test_titanic1(self):\n",
    "        self.assertAlmostEqual(AccEveryoneDies, 61.6161616162)\n",
    "    def test_titanic2(self):\n",
    "        self.assertAlmostEqual(AccGender, 78.6756453423)\n",
    "    def test_titanic3(self):\n",
    "        self.assertAlmostEqual(train['PredEveryoneDies'].mean(), 0.0)\n",
    "    def test_titanic4(self):\n",
    "        self.assertAlmostEqual(train['PredGender'].mean(), 0.35241301908)\n",
    "    def test_titanic5(self):\n",
    "        self.assertTrue(['PassengerId', 'Survived']==list(pd.read_csv('submiteveryonedies.csv').columns.values))\n",
    "    def test_titanic6(self):\n",
    "        self.assertAlmostEqual(train['PredGenderAge13'].mean(), 0.393939393939)\n",
    "    def test_titanic7(self):\n",
    "        self.assertAlmostEqual(train['PredGenderAge18'].mean(), 0.417508417508)\n",
    "    def test_titanic8(self):\n",
    "        self.assertAlmostEqual(AccGenderAge13, 79.2368125701)\n",
    "    def test_titanic9(self):\n",
    "        self.assertAlmostEqual(AccGenderAge18, 77.3288439955)\n",
    "    def test_titanic10(self):\n",
    "        self.assertTrue(train['child'].sum()==69)\n",
    "    def test_titanic11(self):\n",
    "        self.assertTrue(test['child'].sum()==25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a collection of all of the tests from the exercises above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [ad]",
   "language": "python",
   "name": "Python [ad]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
